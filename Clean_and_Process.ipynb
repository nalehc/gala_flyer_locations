{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a library 'pandas', names it as 'pd'\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# enables inline plots, without it plots don't show up in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to write a small function which returns the list of weeks in an appropriate format.  The function will take 'month' and 'yrs_back' as an input and then return a list of weeks going 'yrs_back' number of years back.  For instance, get_weeks_nums(3,2) gives all the weeks in march for two years back, starting from the most recent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time(num):\n",
    "    if len(str(num)) == 2:\n",
    "        return str(num)\n",
    "    else:\n",
    "        return '0'+str(num)\n",
    "\n",
    "def get_week_nums(month,yrs_back):\n",
    "    week_list=[]\n",
    "    ref_date=datetime.date(2018,6,30)\n",
    "    weeks_back=yrs_back*52\n",
    "    for i in range(weeks_back):\n",
    "        week_shift=datetime.timedelta(-7*i)\n",
    "        new=ref_date+week_shift\n",
    "        yr=str(new.year)[-2:]\n",
    "        mt=fix_time(new.month)\n",
    "        day=fix_time(new.day)\n",
    "        string=yr+mt+day\n",
    "        if int(mt)==month:\n",
    "            week_list.append(int(string))\n",
    "    return week_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "#I am going to focus on June for the last 3 years.\n",
    "week_nums = get_week_nums(6,3)\n",
    "df = scrape(week_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_180630.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols={x:x.strip() for x in df.columns}\n",
    "df_ren=df.rename(columns=cols)\n",
    "#df_small=df_ren[:1000]\n",
    "df_small=df_ren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to extract a time stampe from a given row in the dataframe.  The following is an example of how to do this for a particular row.  In the next frame we do this for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-23 04:00:00')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df_small.iloc[1][6]+' '+df_small.iloc[1][7],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(x):\n",
    "    return pd.to_datetime(x[6]+' '+x[7],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2547963"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['datetime']=df_small.apply(get_datetime,axis=1)\n",
    "#df_small.iloc[:100000].apply(get_datetime,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_clean=df_small.drop_duplicates(subset=['C/A','UNIT','SCP','STATION','LINENAME','datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should group by station and datetime **then** resample to make sure that we only have proper intervales of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_clean2=df_small_clean.groupby(['STATION','datetime'])[['EXITS']].sum()\n",
    "df_small_clean3=df_small_clean2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get diffs for each station, which means we need to find a list of stations, go by each one, sort by datetime, resample do a diff operation, etc.  The following takes in a dataframe like df_small_clean3 and a station and then gives back a dataframe for that particular station with the indices sorted by datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_activity(df,station):\n",
    "    df_station=df[df['STATION']==station]\n",
    "    df_sort=df_station.sort_values(by=['datetime'])\n",
    "    return df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>datetime</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58360</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 00:00:00</td>\n",
       "      <td>955460529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58361</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 04:00:00</td>\n",
       "      <td>955461609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58362</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 08:00:00</td>\n",
       "      <td>955464213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58363</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>955471806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58364</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 16:00:00</td>\n",
       "      <td>955480958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATION            datetime      EXITS\n",
       "58360   59 ST 2016-05-28 00:00:00  955460529\n",
       "58361   59 ST 2016-05-28 04:00:00  955461609\n",
       "58362   59 ST 2016-05-28 08:00:00  955464213\n",
       "58363   59 ST 2016-05-28 12:00:00  955471806\n",
       "58364   59 ST 2016-05-28 16:00:00  955480958"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_activity(df_small_clean3,'59 ST').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now for each station, apply a re-sample and then a diff map and drop the first element.  First, make a dataframe for each station, combine these in a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In writing the following definitions we are requring the seconds to be zero.  This is just a simple way to get rid of the wierd entries.\n",
    "\n",
    "Note that in the next iteration we could instead do the following:  Resample both datasets hourly.  Simply take averages within each time window and then treat both datasets uniformally.  Still nead to drop wierd times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_time_mask(df):\n",
    "    masks=[]\n",
    "    for i in range(len(df)):\n",
    "        test=(df['datetime'].iloc[i].hour%4==0)&(df['datetime'].iloc[i].second==0)        \n",
    "        masks.append(test)\n",
    "    return pd.Series(masks)\n",
    "\n",
    "def bad_time_mask(df):\n",
    "    masks=[]\n",
    "    for i in range(len(df)):\n",
    "        test=(df['datetime'].iloc[i].hour%4!=0)&(df['datetime'].iloc[i].second==0)\n",
    "        masks.append(test)\n",
    "    return pd.Series(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Hereby Declare:  All bad-time index sets will just be mapped to good time indices by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m3=good_time_mask(df_small_clean3)\n",
    "#df_small_clean3[m3];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we demonstrate how the time deltas can be used to shift the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, Timestamp('2018-06-23 00:00:00'))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts=df_small_clean3.iloc[0][1]\n",
    "t_delta=datetime.timedelta(0,0,0,0,0,2)\n",
    "ts.second, ts-t_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In the next step we write a function to shift the times on the rows of the bad times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_time(row):\n",
    "    t_delta=datetime.timedelta(0,0,0,0,0,2)\n",
    "    ts=row[1]\n",
    "    row[1]=ts-t_delta\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see that shift_time works on a particular row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/williamcottrell72/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "STATION                    1 AV\n",
       "datetime    2016-05-27 22:00:00\n",
       "EXITS                3476159310\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_time(df_small_clean3.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write a function which takes in a dataframe and sets all the times to the proper intervales.  Basically, we break the dataframe into 'bad' and 'good' pieces and apply the shift to the bad pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_to_good(df):\n",
    "    gm=good_time_mask(df)\n",
    "    bm=bad_time_mask(df)\n",
    "    g_df=df[gm]\n",
    "    b_df=df[bm]\n",
    "    b2g_df=b_df.apply(shift_time,axis=1)\n",
    "    fin=pd.concat([g_df,b2g_df],ignore_index=True)\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_clean4=bad_to_good(df_small_clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go by station and for each station, apply the diff operation, obtaining a list of dataframes containing the diff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations=df_small_clean4['STATION'].unique()\n",
    "station_diffs_dct={}\n",
    "for st in stations:\n",
    "    sa=station_activity(df_small_clean4,st)\n",
    "    st_diffs=pd.DataFrame(sa['EXITS'].diff()).dropna()\n",
    "    sa['EXITS']=st_diffs['EXITS']\n",
    "    sa=sa.rename(columns={'EXITS':'diffs'})\n",
    "    station_diffs_dct[st]=sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add a column for weekday and an hour, dropna, group by weekday and hour. Note that many of the cleaning steps below could be incorporated above when the dictionary is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_df=station_diffs_dct['59 ST'].dropna()\n",
    "#st_df_filt=st_df[np.abs(st_df.diffs)<20000]\n",
    "#st_df_filt['weekday']=st_df_filt['datetime'].apply(lambda x: x.weekday())\n",
    "#st_df_filt['hour']=st_df_filt['datetime'].apply(lambda x: x.hour)\n",
    "#st_df_clean2=st_df_filt.groupby(['weekday','hour'])['diffs'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/williamcottrell72/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/williamcottrell72/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dct_clean={}\n",
    "for st in stations:\n",
    "    st_df=station_diffs_dct[st].dropna()\n",
    "    st_df_filt=st_df[np.abs(st_df.diffs)<20000]\n",
    "    st_df_filt['weekday']=st_df_filt['datetime'].apply(lambda x: x.weekday())\n",
    "    st_df_filt['hour']=st_df_filt['datetime'].apply(lambda x: x.hour)\n",
    "    st_df_clean2=st_df_filt.groupby(['weekday','hour'])['diffs'].mean()\n",
    "    dct_clean[st]=st_df_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday  hour\n",
       "0        3        354.923077\n",
       "         7       2859.583333\n",
       "         11      3292.692308\n",
       "         15      4609.000000\n",
       "         19      5919.153846\n",
       "         23      2457.153846\n",
       "1        3        318.538462\n",
       "         7       3544.846154\n",
       "         11      3913.846154\n",
       "         15      5212.000000\n",
       "Name: diffs, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_clean['103 ST'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_by_time(day,hour):\n",
    "    #We must convert a 24hour of the day to one of 0,4,8...\n",
    "    h2=((hour//4+1)*4)%24\n",
    "    exits=[]\n",
    "    for st in stations:\n",
    "        try:\n",
    "            leaving=dct_clean[st][day][h2]\n",
    "            exits.append([st,leaving])\n",
    "        except(KeyError,IndexError):\n",
    "            pass\n",
    "    sort_exits=sorted(exits,key=lambda x: x[1])[::-1]    \n",
    "    return sort_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inputting the time remember that Monday is zero, Tuesday is 1, etc.  The hour may be input as an integer and it internally converts to one of the time intervals [0,4], [4,8], etc.  The result appears in order from largest flux to smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['59 ST COLUMBUS', 19556.0],\n",
       " ['CHAMBERS ST', 18097.076923076922],\n",
       " ['50 ST', 15084.615384615385],\n",
       " ['JOURNAL SQUARE', 14687.0],\n",
       " ['BOWLING GREEN', 13463.153846153846],\n",
       " ['51 ST', 11969.181818181818],\n",
       " ['JAY ST-METROTEC', 9185.0],\n",
       " ['49 ST', 8690.615384615385],\n",
       " ['BOROUGH HALL', 8452.272727272728],\n",
       " ['BROOKLYN BRIDGE', 8038.461538461538],\n",
       " ['ATL AV-BARCLAY', 7503.384615384615],\n",
       " ['FLUSHING-MAIN', 6959.916666666667],\n",
       " ['WALL ST', 6828.428571428572],\n",
       " ['GRAND ST', 6779.0],\n",
       " ['168 ST', 6646.833333333333],\n",
       " ['5 AV/53 ST', 6116.692307692308],\n",
       " ['34 ST-PENN STA', 6049.4],\n",
       " ['5 AVE', 5838.692307692308],\n",
       " ['42 ST-PORT AUTH', 5708.6],\n",
       " ['COURT SQ', 5400.076923076923],\n",
       " ['JAMAICA CENTER', 5348.416666666667],\n",
       " ['1 AV', 5226.416666666667],\n",
       " ['LEXINGTON AV/63', 4864.538461538462],\n",
       " ['34 ST-HUDSON YD', 4811.384615384615],\n",
       " ['SPRING ST', 4796.846153846154],\n",
       " ['PRINCE ST', 4765.076923076923],\n",
       " ['BEDFORD AV', 4466.916666666667],\n",
       " ['RECTOR ST', 4456.153846153846],\n",
       " ['WORLD TRADE CTR', 4375.846153846154],\n",
       " ['145 ST', 4304.153846153846],\n",
       " ['JKSN HT-ROOSVLT', 4105.0],\n",
       " ['NOSTRAND AV', 3652.923076923077],\n",
       " ['KEW GARDENS', 3581.818181818182],\n",
       " ['33 ST-RAWSON ST', 3562.0],\n",
       " ['5 AV/59 ST', 3360.6153846153848],\n",
       " ['57 ST-7 AV', 3317.0],\n",
       " ['2 AV', 3298.076923076923],\n",
       " ['SUTPHIN-ARCHER', 3295.4615384615386],\n",
       " ['8 ST-NYU', 3217.153846153846],\n",
       " ['82 ST-JACKSON H', 2943.769230769231],\n",
       " ['HOYT-SCHER', 2807.769230769231],\n",
       " ['NEVINS ST', 2692.769230769231],\n",
       " ['DEKALB AV', 2631.923076923077],\n",
       " ['HIGH ST', 2543.5384615384614],\n",
       " ['161/YANKEE STAD', 2477.846153846154],\n",
       " ['HOYT ST', 2158.6923076923076],\n",
       " ['CROWN HTS-UTICA', 2148.1666666666665],\n",
       " ['3 AV', 2131.846153846154],\n",
       " ['18 ST', 2012.4615384615386],\n",
       " ['VERNON-JACKSON', 1891.5454545454545],\n",
       " ['3 AV-149 ST', 1885.076923076923],\n",
       " ['CHRISTOPHER ST', 1851.923076923077],\n",
       " ['BRIGHTON BEACH', 1747.9166666666667],\n",
       " ['STEINWAY ST', 1741.3846153846155],\n",
       " ['BLEECKER ST', 1673.6923076923076],\n",
       " ['110 ST', 1670.0],\n",
       " ['CITY HALL', 1645.1666666666667],\n",
       " ['EAST BROADWAY', 1606.6666666666667],\n",
       " ['JUNCTION BLVD', 1563.5833333333333],\n",
       " ['CENTRAL PK N110', 1475.3076923076924],\n",
       " ['GREENPOINT AV', 1471.5833333333333],\n",
       " ['103 ST-CORONA', 1417.8461538461538],\n",
       " ['149/GRAND CONC', 1414.6923076923076],\n",
       " ['4AV-9 ST', 1406.6923076923076],\n",
       " ['MYRTLE-WYCKOFF', 1352.8461538461538],\n",
       " ['SMITH-9 ST', 1347.6923076923076],\n",
       " ['40 ST LOWERY ST', 1282.3076923076924],\n",
       " ['21 ST-QNSBRIDGE', 1254.923076923077],\n",
       " ['BROADWAY JCT', 1249.2307692307693],\n",
       " ['FORDHAM RD', 1240.3846153846155],\n",
       " ['191 ST', 1229.8461538461538],\n",
       " ['WESTCHESTER SQ', 1221.076923076923],\n",
       " ['46 ST BLISS ST', 1149.1538461538462],\n",
       " ['63 DR-REGO PARK', 1122.5454545454545],\n",
       " ['CARROLL ST', 1079.1538461538462],\n",
       " ['QUEENSBORO PLZ', 1069.076923076923],\n",
       " ['167 ST', 1056.7692307692307],\n",
       " ['90 ST-ELMHURST', 1037.4615384615386],\n",
       " ['30 AV', 1029.5],\n",
       " ['GRAND-NEWTOWN', 987.6923076923077],\n",
       " ['GRAHAM AV', 987.4615384615385],\n",
       " ['JAMAICA 179 ST', 976.3846153846154],\n",
       " ['EASTN PKWY-MUSM', 953.6923076923077],\n",
       " ['175 ST', 931.0],\n",
       " ['UNION ST', 929.6153846153846],\n",
       " ['169 ST', 908.4615384615385],\n",
       " ['4 AV-9 ST', 907.4615384615385],\n",
       " ['6 AV', 889.3636363636364],\n",
       " ['PROSPECT PARK', 887.7692307692307],\n",
       " ['ASTORIA DITMARS', 886.0769230769231],\n",
       " ['53 ST', 879.6666666666666],\n",
       " ['BOWERY', 868.2307692307693],\n",
       " ['BURNSIDE AV', 866.5],\n",
       " ['PARSONS BLVD', 856.9166666666666],\n",
       " ['36 AV', 852.4],\n",
       " ['ROOSEVELT ISLND', 851.2307692307693],\n",
       " ['FAR ROCKAWAY', 845.6923076923077],\n",
       " ['ASTORIA BLVD', 827.0769230769231],\n",
       " ['PELHAM BAY PARK', 808.7692307692307],\n",
       " ['NASSAU ST', 773.3333333333334],\n",
       " ['NASSAU AV', 755.4444444444445],\n",
       " ['MORGAN AV', 726.4615384615385],\n",
       " ['KINGSTON-THROOP', 725.6923076923077],\n",
       " ['CASTLE HILL AV', 704.6923076923077],\n",
       " ['39 AV', 701.3076923076923],\n",
       " ['COURT SQ-23 ST', 698.4615384615385],\n",
       " ['NEW LOTS AV', 696.5384615384615],\n",
       " ['AVENUE M', 691.7692307692307],\n",
       " ['W 8 ST-AQUARIUM', 688.3333333333334],\n",
       " ['MT EDEN AV', 673.6153846153846],\n",
       " ['SUTTER AV-RUTLD', 665.7272727272727],\n",
       " ['CLASSON AV', 663.3076923076923],\n",
       " ['74 ST-BROADWAY', 652.5384615384615],\n",
       " ['CLARK ST', 646.7692307692307],\n",
       " ['25 ST', 642.9230769230769],\n",
       " ['SARATOGA AV', 632.3333333333334],\n",
       " ['PRESIDENT ST', 632.0769230769231],\n",
       " ['138/GRAND CONC', 625.4615384615385],\n",
       " ['KINGSTON AV', 619.9230769230769],\n",
       " ['MONTROSE AV', 619.25],\n",
       " ['45 ST', 612.3076923076923],\n",
       " ['OZONE PK LEFFRT', 609.0],\n",
       " ['MORISN AV/SNDVW', 589.4166666666666],\n",
       " ['18 AV', 558.0],\n",
       " ['GRAND ARMY PLAZ', 535.7692307692307],\n",
       " ['176 ST', 532.0769230769231],\n",
       " ['AVENUE J', 532.0],\n",
       " ['67 AV', 519.1666666666666],\n",
       " ['EUCLID AV', 505.15384615384613],\n",
       " ['BEDFORD-NOSTRAN', 500.15384615384613],\n",
       " ['207 ST', 493.38461538461536],\n",
       " ['BAY RIDGE-95 ST', 488.6923076923077],\n",
       " ['GRANT AV', 446.0],\n",
       " ['BAY RIDGE AV', 443.0],\n",
       " ['183 ST', 441.15384615384613],\n",
       " ['HARLEM 148 ST', 439.0769230769231],\n",
       " ['15 ST-PROSPECT', 405.15384615384613],\n",
       " ['V.CORTLANDT PK', 402.0],\n",
       " ['ST LAWRENCE AV', 399.15384615384613],\n",
       " ['STERLING ST', 390.53846153846155],\n",
       " ['WILSON AV', 374.53846153846155],\n",
       " ['174-175 STS', 365.38461538461536],\n",
       " ['AVENUE H', 364.84615384615387],\n",
       " ['75 ST-ELDERTS', 339.15384615384613],\n",
       " ['OCEAN PKWY', 337.0769230769231],\n",
       " ['PENNSYLVANIA AV', 328.3333333333333],\n",
       " ['ELMHURST AV', 312.9166666666667],\n",
       " ['55 ST', 307.15384615384613],\n",
       " ['JEFFERSON ST', 300.53846153846155],\n",
       " ['CORTELYOU RD', 294.53846153846155],\n",
       " ['JUNIUS ST', 271.7],\n",
       " ['AVENUE X', 251.84615384615384],\n",
       " ['BEVERLEY ROAD', 251.53846153846155],\n",
       " ['WHITLOCK AV', 248.53846153846155],\n",
       " ['BEACH 67 ST', 243.69230769230768],\n",
       " ['85 ST-FOREST PK', 239.07692307692307],\n",
       " ['CITY / BUS', 238.0],\n",
       " ['BEACH 60 ST', 237.30769230769232],\n",
       " ['215 ST', 232.76923076923077],\n",
       " ['WOODLAWN', 230.23076923076923],\n",
       " ['182-183 STS', 227.30769230769232],\n",
       " ['BRIARWOOD', 226.46153846153845],\n",
       " ['190 ST', 223.6153846153846],\n",
       " ['BEACH 25 ST', 218.84615384615384],\n",
       " ['71 ST', 208.46153846153845],\n",
       " ['231 ST', 199.76923076923077],\n",
       " ['BUSHWICK AV', 173.3846153846154],\n",
       " ['MARBLE HILL-225', 158.23076923076923],\n",
       " ['ATLANTIC AV', 154.53846153846155],\n",
       " ['AVENUE P', 139.23076923076923],\n",
       " ['CYPRESS HILLS', 120.07692307692308],\n",
       " ['BEACH 36 ST', 116.61538461538461],\n",
       " ['121 ST', 112.38461538461539],\n",
       " ['BEVERLY RD', 108.15384615384616],\n",
       " ['104 ST', 105.08333333333333],\n",
       " ['NECK RD', 96.84615384615384],\n",
       " ['EXCHANGE PLACE', 75.0],\n",
       " ['BEACH 44 ST', 74.53846153846153],\n",
       " ['75 AV', 71.76923076923077],\n",
       " ['PAVONIA/NEWPORT', 63.0],\n",
       " ['LACKAWANNA', 61.5],\n",
       " ['NEWARK BM BW', 37.0],\n",
       " ['PATH WTC', 33.0],\n",
       " ['AQUEDUCT RACETR', 31.153846153846153],\n",
       " ['TWENTY THIRD ST', 9.0],\n",
       " ['NEWARK C', 2.0],\n",
       " ['ORCHARD BEACH', 0.07692307692307693],\n",
       " ['TOMPKINSVILLE', 0.0],\n",
       " ['ST. GEORGE', 0.0]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_by_time(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3251.3846153846152"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_clean['40 ST LOWERY ST'][3][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
