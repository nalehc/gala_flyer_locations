{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a library 'pandas', names it as 'pd'\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from bisect import bisect\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# enables inline plots, without it plots don't show up in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to write a function that scrapes the data from the ny mta website.  The url for the pages containing the data end with a *week-number* specifying the week when the data was taken.  This number is a 6-digit number like *180623*, which means *June 23, 2018*.  Starting from a given known week, we want to go back for a specified number of years, collecting data from a specific month.\n",
    "\n",
    "To do this, we need to first write a small function which returns the list of week- numbers in the appropriate format.  The function will take 'month' and 'yrs_back' as arguments and then return a list of week-numbers going 'yrs_back' number of years back.  For instance, **get_weeks_nums(3,2)** gives all the weeks in march for two years back, starting from the most recent dataset.  The function **fix_time** just helps a bit with formatting.\n",
    "\n",
    "Finally, we want to scrape the data from the website by looking up all the url's with the appropriate week-numbers.  This is accomplished in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_time(num):\n",
    "    if len(str(num)) == 2:\n",
    "        return str(num)\n",
    "    else:\n",
    "        return '0'+str(num)\n",
    "\n",
    "def get_week_nums(month,yrs_back):\n",
    "    week_list=[]\n",
    "    ref_date=datetime.date(2018,6,30)\n",
    "    weeks_back=yrs_back*52\n",
    "    for i in range(weeks_back):\n",
    "        week_shift=datetime.timedelta(-7*i)\n",
    "        new=ref_date+week_shift\n",
    "        yr=str(new.year)[-2:]\n",
    "        mt=fix_time(new.month)\n",
    "        day=fix_time(new.day)\n",
    "        string=yr+mt+day\n",
    "        if int(mt)==month:\n",
    "            week_list.append(int(string))\n",
    "    return week_list\n",
    "\n",
    "def scrape(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "#I am going to focus on June for the last 3 years.\n",
    "week_nums = get_week_nums(6,3)\n",
    "df = scrape(week_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient to strip off the whitespace around the column names.  The name *df_small* is poorly chosen, but I'm too lazy to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols={x:x.strip() for x in df.columns}\n",
    "df_small=df.rename(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to extract a time stampe from a given row in the dataframe.  The following is an example of how to do this for a particular row.  Once we know how to do this on a given row we can write a function which takes in a row and returns a timestamp.  We can then apply this function to the dataframe and add a new column with the 'datetime' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-23 04:00:00')"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df_small.iloc[1][6]+' '+df_small.iloc[1][7],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(x):\n",
    "    return pd.to_datetime(x[6]+' '+x[7],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['datetime']=df_small.apply(get_datetime,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we do some cleaning.  The function 'fn' allows us to get rid of elements which don't have zero seconds.  These appear to be spurious. (Perhaps these represent cases where the turnstile data was recorded mid-period for some reason.) Since the data is cumulative, removing a row will not affect subsequent calculations.  We will also drop duplicate information.  From visual inspection, the duplicates appear to be situations where the data was lost, recovered, and re-found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(row):\n",
    "    return row['datetime'].second==0\n",
    "\n",
    "df_small_clean=df_small[df_small.apply(fn,axis=1)].drop_duplicates(subset=['C/A','UNIT','SCP','STATION','LINENAME','datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps, clean2 and clean3 allow us to focus on the relevant information, i.e., data at the station and time level.  We really don't care about the particular turnstile.  Looking at the particular turnstile could be useful in principle, but, in practice, the person handing out fliers will just go to the specified station and then figure out where the people are.  In the worse case, he/she might have to walk across the street.  However, the data will not be as useful as what the solictor sees on the ground and so we'll leave this to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_clean2=df_small_clean.groupby(['STATION','datetime'])[['EXITS']].sum()\n",
    "df_small_clean3=df_small_clean2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get diffs for each station, which means we need to find a list of stations, go by each station, sort by datetime, then do a diff operation, etc.  \n",
    "\n",
    "As a first step, we want a function which inputs a dataframe and station and then gets only the data relevant to that station.  The function will also sort by datetime for later convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_activity(df,station):\n",
    "    df_station=df[df['STATION']==station]\n",
    "    df_sort=df_station.sort_values(by=['datetime'])\n",
    "    return df_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of what this function does on dataframes formatted like df_small_clean3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>datetime</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58360</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 00:00:00</td>\n",
       "      <td>955460529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58361</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 04:00:00</td>\n",
       "      <td>955461609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58362</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 08:00:00</td>\n",
       "      <td>955464213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58363</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>955471806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58364</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-05-28 16:00:00</td>\n",
       "      <td>955480958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATION            datetime      EXITS\n",
       "58360   59 ST 2016-05-28 00:00:00  955460529\n",
       "58361   59 ST 2016-05-28 04:00:00  955461609\n",
       "58362   59 ST 2016-05-28 08:00:00  955464213\n",
       "58363   59 ST 2016-05-28 12:00:00  955471806\n",
       "58364   59 ST 2016-05-28 16:00:00  955480958"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_activity(df_small_clean3,'59 ST').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go by station and for each station, apply the diff operation, obtaining a list of dataframes containing the diff values.  The list is actually stored as a dictionary, 'station_diffs_dct' since we want to call the entries by the station names rather than a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/williamcottrell72/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/williamcottrell72/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "stations=df_small_clean3['STATION'].unique()\n",
    "station_diffs_dct={}\n",
    "for st in stations:\n",
    "    sa=station_activity(df_small_clean3,st)\n",
    "    sa['diffs']=pd.DataFrame(sa['EXITS'].diff())\n",
    "    st_diffs=sa.drop(['EXITS'],axis=1).dropna()\n",
    "    st_diffs_clean=st_diffs[np.abs(st_diffs.diffs)<10**6]    \n",
    "    st_diffs_clean['weekday']=st_diffs_clean['datetime'].apply(lambda x: x.weekday())\n",
    "    st_diffs_clean['hour']=st_diffs_clean['datetime'].apply(lambda x: x.hour)\n",
    "    st_diffs_clean2=st_diffs_clean.groupby(['weekday','hour'])['diffs'].mean()\n",
    "    station_diffs_dct[st]=st_diffs_clean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example of what this does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday  hour\n",
       "0        0        2638.454545\n",
       "         4         552.076923\n",
       "         8        7175.666667\n",
       "         12      18147.636364\n",
       "         16       9420.000000\n",
       "         20       9763.153846\n",
       "1        0        2931.583333\n",
       "         4         538.538462\n",
       "         8        8619.166667\n",
       "         12      22129.000000\n",
       "         16      10903.583333\n",
       "         20      11548.230769\n",
       "2        0        3706.384615\n",
       "         4         580.769231\n",
       "         8        8597.833333\n",
       "         12      22243.083333\n",
       "         16      11222.230769\n",
       "         20      11751.538462\n",
       "3        0        3873.833333\n",
       "         4         612.666667\n",
       "         8        8522.846154\n",
       "         12      21888.083333\n",
       "         16      10977.461538\n",
       "         20      11228.230769\n",
       "4        0        3690.307692\n",
       "         4         645.846154\n",
       "         8        7772.166667\n",
       "         12      19652.666667\n",
       "         16      10803.384615\n",
       "         20      10285.307692\n",
       "5        0        3948.000000\n",
       "         4        1055.769231\n",
       "         8        2536.615385\n",
       "         12       7311.846154\n",
       "         16       8522.153846\n",
       "         20       7064.250000\n",
       "6        0        3595.750000\n",
       "         4         931.076923\n",
       "         8        1476.769231\n",
       "         12       5482.230769\n",
       "         16       7529.000000\n",
       "         20       6054.250000\n",
       "Name: diffs, dtype: float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_diffs_dct['59 ST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want a function which allows us to input a day of the week and a time and then return a list of stations.  It is a little bit problematic that different stations have data collected on different schedules.  No problem.  We just need to wite a function which takes the collection hours of a given station and then, for the hour input by the user, figures out when the next appropriate hour for that station is.  The function **find_key** below does this.  Our final function **activity_by_time** provides a list for the desired day + time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(num,hours_list):\n",
    "    sort=sorted(hours_list)\n",
    "    pos=bisect(sort,num)\n",
    "    if pos < len(sort):\n",
    "        return sort[pos]\n",
    "    else:\n",
    "        return sort[0]\n",
    "    \n",
    "def activity_by_time(day,hour):\n",
    "    #We must convert a 24hour of the day to one of 0,4,8...\n",
    "    exits=[]\n",
    "    for st in stations:\n",
    "        try:\n",
    "            #hours_st=[x.hour for x in station_diffs_dct[st]['datetime'][:6]]\n",
    "            hours_st=station_diffs_dct[st][0].keys().values\n",
    "            sh=sorted(hours_st)\n",
    "            h_key=find_key(hour,sh)\n",
    "            leaving=station_diffs_dct[st][day][h_key]/4\n",
    "            exits.append([st,leaving])\n",
    "        except(KeyError,IndexError,AttributeError):\n",
    "            pass\n",
    "    sort_exits=sorted(exits,key=lambda x: x[1])[::-1]    \n",
    "    return sort_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done.  When inputting the time remember that Monday is zero, Tuesday is 1, etc.  The hour may be input as an integer and it internally converts to the appropriate time interval for the given station using the find_key function.  Below is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['JEFFERSON ST', 8948.403846153846],\n",
       " ['14 ST-UNION SQ', 5806.954545454545],\n",
       " ['JOURNAL SQUARE', 3806.1666666666665],\n",
       " ['W 4 ST-WASH SQ', 2929.653846153846],\n",
       " ['7 AV', 2355.5625],\n",
       " ['34 ST-HERALD SQ', 2351.6346153846152],\n",
       " ['72 ST', 2345.4375],\n",
       " ['FLUSHING-MAIN', 2254.923076923077],\n",
       " [\"B'WAY-LAFAYETTE\", 2012.2045454545455],\n",
       " ['KEW GARDENS', 1969.3958333333333]]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_by_time(3,20)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
